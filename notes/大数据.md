







## HDFS

分布式文件系统



## MapReduce

**分布式计算框架**

既是编程模型又是计算框架

### 编程模型

编程模型只包含Map和Reduce两个过程，map的主要输入时一对key和value值，经过map计算后输出一对key和value值。将相同的key合并形成key和value集合，将这个结果输入给reduce去计算输出零个或多个key和value对。

例如：单词统计程序，统计文本中词的频度。可以把统计一行数据的单词频度作为一个map函数，输出对应的key和value表示单词和对应的频度。MapReduce计算框架会把这些key和value对汇总合并，将相同key的value放入同一个集合，然后将这些数据交给reduce函数。reduce对这些value集合做求和。

![img](https://static001.geekbang.org/resource/image/55/ba/5571ed29c5c2254520052adceadf9cba.png)



### 计算框架

以上就是编程模型的主要计算过程和原理，但是这样的一个MapReduce程序要想在分布式环境中执行，并处理海量数据还需要一个计算框架，能够调度执行这个MapReduce程序。而这个计算框架也叫MapReduce。



### 框架怎么运作

两个关键问题：

- 如何为每个数据块分配Map计算任务。也就是如何发送到数据块所在的服务器的，如何启动，启动后如何知道需要计算的数据在什么位置（BlockID是什么）
- 不同服务器的key、value结果怎么把相同key的结果聚合起来发给Reduce任务进行处理。

![https://static001.geekbang.org/resource/image/f3/9c/f3a2faf9327fe3f086ec2c7eb4cd229c.png](https://static001.geekbang.org/resource/image/f3/9c/f3a2faf9327fe3f086ec2c7eb4cd229c.png)



#### MapReduce作业启动和运行机制

以Hadoop为例，MR运行过程涉及三类关键进程

1. 大数据应用进程。启动MapReduce程序的主入口，主要是指定Map和Reduce类，输入输出文件路径等，并提交作业给Hadoop集群，也就是下面提到的JobTracker进程。
2. JobTracker进程。根据要处理的输入数据量，让TaskTracker进程启动相应数量的Map和Reduce进程任务。同时管理整个作业生命周期的任务调度和监控。这是Hadoop集群的常住进程，并且是全局唯一的。
3. TaskTracker进程。负责启动和管理Map进程和Reduce进程，通常和HDFS的DataNode进程启动在同一个服务器。



JobTracker进程和TaskTracker进程是主从关系，主服务器只有一台（可以有多个备份服务器，但只有一个服务器去提供服务），从服务器可能有几百上千台。从服务器听从主服务器的控制和调度安排。主服务器负责为应用程序分配服务器资源以及作业执行的调度，而具体的计算操作则在从服务器上完成。

![img](https://static001.geekbang.org/resource/image/2d/27/2df4e1976fd8a6ac4a46047d85261027.png)



#### 计算流程

1. 应用进程 JobClient 将用户作业 JAR 包存储在 HDFS 中。
2. 应用程序提交job作业给JobTracker。
3. JobTracker根据作业调度策略创建JobInProcess 树，每个作业都会有一个自己的 JobInProcess 树。
4. JobInProcess 根据输入数据分片数目（一般就是分布在不同服务器的数据块的数目）和设置Reduce数据创建相应数量的TaskInProcess。
5. TaskTracker 进程和 JobTracker 进程进行定时通信。如果TaskTracker有空闲计算资源，JobTracker 会给它分配任务。分配任务时根据TaskTracker 的服务器名匹配同一台机器上的数据块进行计算。这样就实现了“移动计算比移动数据更划算”。
6. TaskTracker  收到任务后**根据任务类型**（是 Map 还是 Reduce）和**任务参数**（作业 JAR  包路径、输入数据文件路径、要处理的数据在文件中的起始位置和偏移量、数据块多个备份的 DataNode 主机名等），**启动相应的 Map 或者  Reduce 进程。**
7. Map 或者 Reduce 进程启动后，检查本地是否有要执行任务的 **JAR 包文件**，如果没有，就去 HDFS 上下载，然后加载 Map 或者 Reduce 代码开始执行。
8. 如果是 Map 进程，从 HDFS 读取数据（通常要读取的数据块正好存储在本机）；如果是 Reduce 进程，将结果数据写出到 HDFS。



#### 数据的合并

Map的结果怎么汇总起来让Reduce去处理。MapReduce的处理数据合并和连接操作，成为shuffle。

![img](https://static001.geekbang.org/resource/image/d6/c7/d64daa9a621c1d423d4a1c13054396c7.png)



每个Map任务的计算结果都写入本地文件系统，当快计算完成时，启动shuffle过程，Map任务进程调用一个Partitioner接口，对每个key、value进行Reduce分区选择，然后通过HTTP通信发送给对应的Reduce进程。对用想用的key 的数据肯定会分配到同一个Reduce进程。MapReduce 框架默认的 Partitioner 用 Key 的哈希值对 Reduce 任务数量取模，相同的 Key 一定会落在相同的 Reduce 任务 ID 上。



## 资源调度框架

Yarn是分布式集群的**资源调度框架**，不是Hadoop一开始就有的。它的出现就是为了将计算框架和资源管理解耦。Hadoop2将Yarn从MapReduce中分离出来，成为一个独立的资源调度框架。

![img](https://static001.geekbang.org/resource/image/af/b1/af90905013e5869f598c163c09d718b1.jpg)



### 组成

Yarn包括两个部分：资源管理器（Resource Manager），节点管理器（Node Manager）。也是两种主要进程

- ResourceManager进程。负责整个**集群的资源调度管理**，通常部署在**独立**的服务器上。
  - 资源管理器又分为两个主要组件
    - **调度器**。就是一个资源分配算法，根据应用程序提交的资源申请和当前服务器集群的资源状态进行资源分配。Yarn内置了几种资源调度算法，如Fair Scheduler、Capacity Scheduler等。
      - **Yarn进行资源分配的单位是容器**（Container），每个容器包含一定量的内存、cpu等计算资源，默认配置下每个容器包含一个CPU核心。容器由NodeManager去管理。
    - **应用程序管理器**。负责应用程序的提交、监控应用程序的运行状态等。应用程序启动后会先在一个容器中运行一个ApplicationMaster，由它根据应用程序的资源需求进一步向ResourceManager进程申请容器资源，然后就会在申请到的需要的容器中启动应用程序的相关代码。
- NodeManager进程。负责具体**当前服务器上的资源和任务管理**，在集群的**每一台**计算服务器上都会启动，基本上跟HDFS的DataNode进程一起出现。



### Yarn工作流程

1. 想Yarn提交应用程序。
2. ResourceManager进程和NodeManager进程通信，根据集群资源，为应用程序分配第一个容器，并将MapReduce ApplicationMaster 分发到这个容器上面，并且启动。
3. MapReduce ApplicationMaster 启动后立即向ResourceManager进行注册，并为自己的应用程序申请容器资源。
4. 申请到需要的容器后，立即和相应的NodeManager进程通信，将应用程序的MapReduce程序分发到NodeManager进程所在的服务器，在容器中运行。
5. Map和Reduce在运行期间向MapReduce ApplicationMaster通信，汇报自己的运行状态，如果结束，MapReduce ApplicationMaster会向ResourceManager进程注销并释放所有的容器资源。



## 框架和系统

为什么HDFS叫系统，而MapReduce和Yarn将框架呢。

框架在架构设计上遵循一个重要的设计原则——**依赖倒转原则**。高层模块不能依赖低层模块，而是应该依赖一个抽象或者叫接口，这个抽象是由高层定义，由底层模块实现。

高低层的划分可以体现在调用链上，处于前面的是高层，后面的是低层。比如Java Web应用，Tomcat就是高层模块，而SpringMVC就是相对低层的模块，而对于用户的应用程序就是更低的层，接下来还有服务层、数据持久层。Tomcat可以在不依赖SpringMVC的情况下调用SpringMVC，就是因为两者都依赖J2EE规范。而SpringMVC也不依赖我们的开发者的代码，而去依赖配置文件或者注解。



回到MapReduce 和 Yarn。实现MapReduce接口就能被MapReduce框架调用，在分布式架构中计算大规模数据。实现Yarn接口，就可以被Yarn调度管理，统一安排服务器资源，比如Hadoop  2 的 MapReduce。

HDFS 就不是框架，使用 HDFS 就是直接调用 HDFS 提供的 API 接口，HDFS 作为底层模块被直接依赖。



## 学习方式

关于学习新知识我有一点心得体会想与你分享。我在学习新知识的时候会遵循一个 5-20-2 法则，用 5 分钟的时间了解这个新知识的特点、应用场景、要解决的问题；用 20 分钟理解它的主要设计原理、核心思想和思路；再花 2 个小时看关键的设计细节，尝试使用或者做一个 demo。如果 5 分钟不能搞懂它要解决的问题，我就会放弃；20  分钟没有理解它的设计思路，我也会放弃；2  个小时还上不了手，我也会放一放。你相信我，一种真正有价值的好技术，你这次放弃了，它过一阵子还会换一种方式继续出现在你面前。这个时候，你再尝试用  5-20-2 法则去学习它，也许就能理解了。我学 Hadoop  实际上就是经历了好几次这样的过程，才终于入门。而有些技术，当时我放弃了，它们再也没有出现在我面前，后来它们被历史淘汰了，我也没有浪费自己的时间。



## Hive

Hive用MapReduce实现SQL数据分析。（Hive 的 SQL 语法和数据库标准 SQL 略有不同）

我们通过 Hive 的 Client（Hive  的命令行工具，JDBC 等）向 Hive 提交 SQL 命令。如果是创建数据表的 DDL（数据定义语言），Hive 就会通过执行引擎  Driver 将数据表的信息记录在 Metastore 元数据组件中，这个组件通常用一个关系数据库实现，记录表名、字段名、字段类型、关联  HDFS 文件路径等这些数据库的 Meta 信息（元信息）。如果我们提交的是查询分析数据的 DQL（数据查询语句），Driver  就会将该语句提交给自己的编译器 Compiler 进行语法分析、语法解析、语法优化等一系列操作，最后生成一个 MapReduce  执行计划。然后根据执行计划生成一个 MapReduce 的作业，提交给 Hadoop MapReduce 计算框架处理。





Hive  本身的技术架构其实并没有什么创新，数据库相关的技术和架构已经非常成熟，只要将这些技术架构应用到 MapReduce 上就得到了 Hadoop  大数据仓库 Hive。但是想到将两种技术嫁接到一起，却是极具创新性的，通过嫁接产生出的 Hive 可以极大降低大数据的应用门槛，也使  Hadoop 大数据技术得到大规模普及。



## Spark

### 计算模型

RDD：是Spark的核心概念，是弹性数据集（Resilient Distributed Datasets）的缩写。

**Spark直接针对数据进行编程**，将大规模数据集合抽象成一个RDD对象，然后在这个RDD上进行各种计算，得到新的RDD，继续计算处理，知道得到最后的结果数据。**可以理解为面向对象的大数据计算。**



RDD上定义的函数分为两种：

- 转换函数：返回值还是RDD
  - 比如有计算 map(func)、过滤  filter(func)、合并数据集 union(otherDataset)、根据 Key 聚合 reduceByKey(func,  [numPartitions])、连接数据集 join(otherDataset, [numPartitions])、分组  groupByKey([numPartitions]) 等十几个函数。
  - 转换操作又分为两种，一种转换产生的RDD不会出现新的分片，结果还在当前分片，比如map、filter等。这些操作不会在物理上生成新的RDD，这种特性也被称为惰性计算。
  - 另一种转换产生的RDD会产生新的分片，比如reduceByKey，来自不同分片的相同key必须恤和在一起进行操作，这样就会产生新的RDD分片。
  - 总之Spark应用程序代码中的RDD和Spark执行过程中生成的物理RDD不是一一对应的。
- 执行函数：不返回RDD

RDD也是对大数据进行分片计算，每个RDD分片都会分配到一个执行进程去处理。



### 架构原理

Spark可以根据应用的复杂程度，分割成更多的计算阶段（stage），这些计算阶段组成一个有向无环图DAG，Spark任务调度器可以根据DAG的依赖关系执行计算阶段。

下面图描述了一个典型的Spark运行DAG的不同阶段。

![img](https://static001.geekbang.org/resource/image/c8/db/c8cf515c664b478e51058565e0d4a8db.png)

从图上看，这个应用被切分成三个阶段。阶段3需要依赖阶段1和阶段2，阶段1和阶段2互不依赖。只要根据程序初始化好DAG，就能建立了依赖关系，然后根据依赖关系顺序执行各个计算阶段。

依赖关系清楚之后，再根据每个阶段要处理的数据量生成相应的任务集合（TaskSet），每个任务都分配一个任务进程去处理，就完成大数据的分布式计算。

具体的，负责Spark应用DAG生成和管理的组件是DAGScheduler。它根据程序代码生成DAG，然后将程序分发到分布式计算集群，按计算阶段的先后关系调度执行。



一个RDD包含多个数据分片，一个数据集中的多个数据分片进行分区传输，写到另外的数据集的不同分片中，这个过程MR中也存在，就是shuffle过程，通过shuffle将数据进行重新组合，相同key的数据放在一起进行聚合、关联等操作。

![img](https://static001.geekbang.org/resource/image/d6/c7/d64daa9a621c1d423d4a1c13054396c7.png)



计算阶段的**划分依据是shuffle，不是转换函数类型。**有的函数又shuffle，有的没有。如果结果的分区数据和分区key不变，就不需要进行shuffle。



### 和MapReduce对比

Spark基于数据对象的编程模型，MapReduce是基于过程的编程模型。

Spark相当于将前一个的Reduce和后一个的Map连接起来，当作一个阶段的储蓄计算，本质还是Map和Reduce。Spark优先使用内存进行数据存储，包括RDD数据。除非是内存不够用了，否则是尽可能使用内存。



### 作业管理

Spark 的 DAGScheduler 在遇到 shuffle 的时候，会生成一个计算阶段，在**遇到 action 函数的时候，会生成一个作业（job）。**

RDD里面的每个数据分片，Spark都会创建一个计算任务去处理，所以一个计算阶段会包含很多个计算任务（task）。

作业、任务、计算阶段，三者个关系如下图

![img](https://static001.geekbang.org/resource/image/2b/d0/2bf9e431bbd543165588a111513567d0.png)

纵向的每条红线是任务，是最小的单位。横向是时间。两条粗线之间是一个作业，两条线之间是一个计算阶段。**一个作业至少包含一个计算阶段。**每个计算阶段由很多个任务组成，这些任务组成一个任务集合。

DAGScheduler 根据代码生成 DAG 图以后，Spark 的任务调度就以任务为单位进行分配，将任务分配到分布式集群的不同机器上执行。



### 执行过程

Spark 支持 Standalone、Yarn、Mesos、Kubernetes 等多种部署方案。

下图是Spark的运行流程。

![img](https://static001.geekbang.org/resource/image/16/db/164e9460133d7744d0315a876e7b6fdb.png)



- Driver进程为java进程，启动后调用SparkContext初始化执行配置和输入数据。SparkContext启动DAGScheduler 构造执行的 DAG 图，其分成最小的执行单位——任务。
- Driver向Cluster Manager请求计算资源，用于DAG的分布式计算。Cluster Manager收到请求以后，将Driver的主机地址等信息通知给集群的所有计算节点Worker。
- Worker收到信息以后，根据Driver的主机地址，跟Driver进行通信并注册，然后根据自己的资源向Driver报告自己可以领用的任务数。Driver根据DAG图向注册的Worker分配任务。
- Worker收到任务后，启动Executor进程开始执行任务。先检查自己是否有Driver，没有的话去下载，通过Java反射加载后执行。



## HBase



## 流式计算



