[**首页**](https://github.com/qdw497874677/myNotes/blob/master/首页检索.md)

# 负载均衡

## 概念

将请求分发到多台应用服务器，以此来分散压力的一种架构方式。

## 实现方式

### 重定向

请求都发给前置机，前置机去计算要分配给那个服务器，然后响应给客户端，让客户端重定向。

### 反向代理

请求发给前置机，使用反向代理方式，将请求分发给服务器，客户端不用再请求一次。通常有两种实现，一是交换机实现，另外一种是通过nginx这种软件方式实现

### 数据链路返回

前置机通过给服务器设置虚拟ip和修改mac地址的方式，将请求分发给服务器，服务器处理完直接响应给客户端



## 负载均衡算法

### 轮询法

按请求顺序均匀分配到后端服务器。不关心服务器实际的连接数和当前的系统负载。



### 随机法

通过系统的随机算法，根据服务器的列表大小来随机一台服务器进行访问。访问次数多时，效果类似平均分配。



### 源地址哈希法

根据客户端的ip地址，通过Hash算法得到一个数值，然后对服务器列表大小进行取模，得到服务器序号。这样同一ip当列表不变时，他访问的服务器也不变。



### 加权轮询法

不同的服务器可能配置不相同，抗压能力不同。通过配置不同的权重，去顺序轮询，权重高的会多分配请求。



### 加权随机法

也是加权，通过权重高的随机到的概率高来分配请求



### 最小连接数法

动态**选取当前积压连接数少**的来处理当前请求。



## 一致性Hash

### 背景

当一个单节点的缓存容量不够后，需要增加节点来分库，对于每个key都映射到对应的节点上。如果分布式集群中有个集群宕机了，对应的key的缓存无法存储导致服务器压力过大。对于增加机器时，又需要保证大部分key在原有映射到的服务器上保持不变。

总结：**如何保证分布式集群中添加节点和删除节点，对应key的映射保持稳定。可以通过一致性哈希算法解决。**

如果简单的使用普通Hash算法，得到服务器序号，当服务器数量发生变化，对应key算出来序号都会变化。



这种方式要求增加一台缓存服务器时，新的服务器尽量分担存储其他服务器的缓存资源。减少一台缓存服务器时，其他所有服务器可以尽量分担存储它的缓存资源。



### 实现原理

**一致性哈希算法**主要思想：将每个缓存服务器与一个或多个哈希**值域区间**关联起来，其中区间边界通过计算缓存服务器对应的哈希值来决定。如果一个缓存服务器被移除，则它所对应的区间会被并入到邻近的区间，其他的缓存服务器不需要任何改变。



将映射空间组织成一个环，值的范围为0 - 2^23-1，也就是一个无符号整形的范围。

- 先对服务器进行Hash计算。
- 当请求到来时，对请求进行Hash计算，从计算的哈希值开始顺时针找到第一个服务器的Hash位置，这个服务器就是分配给请求的服务器。

也就是把服务器Hash之前的服务分配给一个服务器。

### 效果

当一个节点A不可用。把他从移除，请求接着顺时针寻找下一个可用节点B。这样原本打到节点A的请求就快速分给节点B，同时不影响打到其他节点的请求。



当需要添加一个节点，比如在A和B中间添加一个C，原本打到B的一部分请求就分配给了，分担了B的请求，同时不影响其他。

### 问题

上面的设置中会有数据倾斜问题。当服务器比较少是，分配在整个区域的位置可能不会很均匀。就会导致请求打到服务器不均匀。

解决：可以在服务器较少的情况下，用多用几个虚拟节点再次映射到对应的服务器上。比如开始只有两个节点A、B。为A和B设置对应的虚拟节点A2、A3、B2、B3，这样总共6个几点，相对会分布均匀一些。对于打到虚拟节点的请求会再次映射到真正的节点上。

# 分布式缓存

缓存的发展：本地缓存 -> 集群缓存 -> 分布式缓存

缓存的好处：

- **加速读写**。缓存一般是把数据存到内存中，
- **降低后端负载**。阻挡大量请求直接落到系统底层。降低后端对CPU、IO、线程这些资源的需求。

带来的问题：

- 数据不一致：存储层和存储层的数据，存在一定时间窗口一致。时间窗口与缓存的过期时间更新策略有关。
- 代码维护成本：加入缓存层后，要同时处理缓存层和存储层的逻辑。
- 运营成本：为了保证高可用，要做主从，做集群



## 缓存更新

对缓存中存储的数据的更新方式，更新包括删除和修改。如果要维持比较好的一致性需要去用比较适合的删除策略和主动更新结合的方式。

### LRU、LFU、FIFO

这三种算法都是在缓存不够用时采用的更新算法。区别是选择要淘汰的数据的规则不一样。

LRU淘汰最久不访问的数据、LFU淘汰操作频率最低的数据、FIFO先进先出。

一致性差

**使用场景**：适合内存空间有限，数据长期不变动，基本不存在数据不一致性的业务。



### 超时删除

给缓存数据设置一个过期时间。当数据在缓存中不存在后，从数据源重新放到缓存中。

数据一致性一般。

**使用场景**：适合能够容忍一定时间内数据不一致的业务，比如促销活动的描述文案。



### 主动更新

如果数据源有更新，则主动更新缓存。

一致性较高。开发维护成本比较高，**业务数据的更新与缓存更新耦合**到了一起。需要处理业务数据更新成功，缓存更新失败的情景。

为了解耦一般用消息队列的方式来更新。为了提高容错率，会结合超时删除的方案，避免缓存得不到更新的场景。

优化：

- **异步更新缓存**：来解耦业务数据更新和缓存更新，提高容错率。
- **结合缓存超时删除**：防止缓存得不到更新的情况。

**使用场景**：对于数据的一致性要求高，比如交易系统，优惠券的总张数。



### 总结

**低一致性业务**：过量删除 + 超时删除

**高一致性业务**：超时删除 + 主动更新



## 缓存更新方案

### 更db，更（删）缓存

写多读少的场景如果总是主动更新缓存的话会造成很多无用的操作，所以更适合直接删除缓存。在查缓存时再从db获取。

可能出现的问题：

- 脏数据
- 更新缓存频繁



### 更缓存，更db

优先更新缓存，然后异步更新数据库。

对于更新频繁的情况可以选择这样，但是如果有大量请求对同一个key做更新，容易发生数据不一致：更新db的操作的覆盖。











## 缓存穿透、击穿

### 穿透

指查询一个不存在的数据，缓存和数据源存储都不能命中。如果没有做处理，大量的请求可能击垮存储层。

有下面方法：

#### 缓存空对象

如果存储层没有查到，就在缓存层中存储一个空的对象。

问题：

- 如果一瞬间有大量不同的请求同时查同一个不存在的数据，在还没有更新缓存空对象时，大量查询还是会穿透到数据层。
- 缓存层中的空对象浪费空间

针对这种方案作出优化：

- 做好业务过滤：通过缩小范围，将越界的请求直接返回，不查询。
- 给缓存的空对象设置较短的过期时间。



#### 布隆过滤器

布隆过滤器是一种**Hash和Bitmap**结合的数据结构。可以把一个值经过不同的Hash得到几个索引值，映射到Bitmap中，设置为1。如果查询时发现对应Hash后的几个索引位都不全是1，说明肯定是不存在的，但是如果全是1，是不一定存在的。

可以优先判断元素是否存在于集合中，在业务中主动更新布隆过滤器。

使用：可以在本地用布隆过滤器去主动缓存，对于漏判的使用空对象处理。

##### 使用

Redis中有bloomfilter插件。常用命令有：

~~~shell
bf.add users user3

bf.exists users user1
~~~



### 击穿

某个热点数据不可用，导致存储层压力增大。

优化方案：主要是优化热点key的重建

- 互斥锁：同时只允许一个线程对缓存重建。用集群服务用分布式锁。
- 永不过期：更新是独立的，主动更新。
- 后端限流：前两个是知道哪些是热点key的情况。如果不知道还得是后端自己做限流，主要安全的更新一个就好了
- 减少同时过期的key：对一批key的过期时间可以设置为一定范围的随机数。
- 热点key预热：在关键时间提前对一些热点数据更新随机的过期时间等。

### 雪崩

大量缓存数据不可使用，所有请求到达存储层，导致存储层宕机。可能是因为大量热点数据同时击穿，或者是缓存服务器宕机。

优化方案：

- 保证缓存层的高可用：比如Redis集群的哨兵机制
- 为后端限流降级：比如用hystrix。
  - 保证还可以处理少量的请求，用户点一次不行多点几次会有。





# 分布式锁

在集群中，多台主机都有一个共同的资源，如果不加分布式锁，不同的访问后，他们的结果可能不一样。

分布式锁需要具备的条件

- 一个方法同一时间只能被一台机器的一个线程执行。
  - （Redis）setnx。
- 获取锁，释放锁要高可用高性能。
  - （Redis）setnx。
- 具备可重用。
  - （Redis）在获取锁的时候，判断当前线程是否已经拿到锁了。然后将计数器加减，每获取一次锁加一，每解锁一次减一。
- 具备锁失效机制，防止死锁。
  - （Redis）设置过期时间，为了保证业务完成，每过一定时间重新设置超时时间 ，让业务异步的执行。
- 具备非阻塞锁特性，即没有获得锁可以返回获取锁失败。
  - （Redis）让线程阻塞，然后利用发布订阅解决实时性。



## Redis实现的分布式锁

### Redis

- 加锁

setnx key value

或者后来另一个方案。set key value ex 10 nx。

在redis中给key设置一个值，为了避免死锁，给定一个过期时间。保证设置值和过期时间在一个原子操作中。

命令在设置成功时返回1，设置失败时返回0。

- 解锁

将客户端自己的锁的key删除。根据值的uuid和线程自己存的uuid，是否相等，相等就说明是自己的锁，才能解锁。

为了保证原子性，用LUA脚本来完成操作。先判断字符串是否相等，相等就删除key。

缺点：锁不是可重入锁。



## Redisson

~~~java
Rlock product = redisson.getLock("priduct");
product.lock();
priduct.unlock();
~~~



# 微服务

## 什么是

将单体应用分成一组小型服务。每个小型服务运行在自己的进程中，之间通过轻量级机制通信（HTTP REST API）。这些服务都是围绕业务建立的，可以独立开发（可用不同语言实现，存储不同数据），独立部署。

## 为什么用微服务

- 有更好的可扩展性：分为三个维度

  - 水平可扩展：部署了一个服务，可以通过部署在多台服务器，增加性能
  - 业务可扩容：把多个业务中的通用的业务提取成服务，把不同的业务提取成为多个服务，来与公共服务连接
  - 数据可扩展：每个服务可以只使用自己需要的数据来源

- 独立发布和部署

- 独立开发：每个服务可以使用独立的技术栈来开发

- 优雅降级：如果单个服务崩溃，影响会比较小，提高整机的健壮性

# RPC

![img](分布式相关.assets/7632302-ca0ba3118f4ef4fb.png)



## RPC和HTTP接口的区别

这两者都可以调用远程的方法。RPC是一种设计，为了解决服务之间的调用问题，包含传输协议和序列化协议，rpc的传输协议可以建立在tcp上，也可以建立在http协议之上。http调用只是遵循http协议的一种传输过程。

HTTP协议支持连接池复用，可以在一个tcp连接中发送多个http请求。对于一个http请求，报文中的信息密度不高。RPC可以自定义数据整体，可增大数据密度来针对不同类型。

对于http2.0的编码问题已经不是最终问题了，主要是，RPC内部也可以使用HTTP请求来通信，同时也可以自定义自己的数据传输。RPC还包含很多服务治理相关的功能，包括服务发现，负载均衡，熔断等





## Thrift



## 实现一个简单的RPC

RPC框架可以实现，在客户端直接调用服务端的方法，就像调用本地方法一样。



## Dubbo的基本使用

在客户端通过@Reference注解加载接口引用上，就获得一个接口的实现类，对于客户端就可以直接调用了，而真正的服务是写在服务端的。

在服务端创建对应接口的实现类，来类上写上Dubbo的@Service，这个实现类注册到了Dubbo框架中。

## 基本原理

客户端得到的接口实例，并不是在服务器端提供的实现类实例，而是RPC框架提供的一个代理类实例，称为桩（Stub）。

不同的RPC框架中，桩的生成方式不一样，**有的是在编译阶段生成，有的是在运行时动态生成。**

### **桩**

桩要实现接口，供客户端去调用。**桩实现的方法中会构造一个请求**，然后发送给服务端。这个请求就是一段数据结构，包含两个重要的信息：

1. **请求的服务名**，一般表示为：接口名#方法明和参数。
2. **请求的所有参数**，包括参数类型和具体的值。

然后它会把这个请求发送给服务端，等待服务的响应。

服务端的RPC框架收到请求后，先把**服务名解析**出来，然后根据这个服务名在注册到RPC框架中的实现类中寻找对应服务提供者。找到后会使用请求中的参数来调用实现类的方法，**将返回结果封装成响应返回**给客户端。

![img](分布式.assets/946841b09cab0b11ce349a5a1eeea0ea.jpg)



### 客户端怎么找到服务端地址

需要有中间件作为一个注册中心。服务端的业务代码向RPC框架中注册服务之后，就会把服务的名称的地址发布到注册中心中。客户端的桩在调用前，会向注册中心请求服务端的地址，请求的**参数就是服务名称**，注册中心会返回服务的地址，然后客户端去请求服务端。

### IDL

对于跨语言的RPC框架，本质和普通RPC是一样的，只要在RPC框架中使用相同的序列化协议，就可以实现跨语言通信。

为了在不同的语言中能描述相同的服务定义，还需要提供一套通用的描述服务的语言，成为IDL（Interface description language）接口描述语言。所有的服务都需要用IDL定义，再由RPC框架转换为特定的编程语言的接口或者实现类。





# 测试接口的工具

postman、jmeter



# 秒杀

特点：时间极短、瞬间用户量大

对于秒杀商品这种高并发场景，要怎么处理？

## 问题

- 超卖
- 恶意请求：机器把商品全部抢走
- 连接暴露：开发者提前知道链接。出现内部秒杀
- 数据库压力



## 解决

![img](分布式相关.assets/640)



- **服务单一职责**
  - 用微服务的思想，把各个业务拆分成服务。秒杀作为一个单独的微服务。单独建立一个秒杀数据库。其他的有短信服务、数据分析服务订单服务等等。
  - 好处就是秒杀服务崩了，不会影响其他服务。
- **秒杀链接加盐**
  - 将秒杀URL动态化，写代码的人也不知道链接。
  - 秒杀开始前设置一个随机数作为盐，通过MD5加密后，提供一个接口来获取这个盐。前端发送秒杀请求时，先获取加密的盐，秒杀请求需要带上这个参数。服务端去解密出盐来对比，如果相等就进行秒杀逻辑。
- **Redis集群**
  - 搭建集群、主从同步、独写分离、持久化，来提高服务的可用性
- **负载均衡**
  - 对秒杀服务，横向扩展。用Nginx或者网关服务去做负载均衡，让多实例分担流量。
  - 同时也去拦截而已请求，对单个用户流量做限流
- **资源静态化**
  - 前端做好静态资源的缓存，把能放的都放进CDN服务器
- **按钮控制**
  - 通过按钮限制用户操作
- **物理限流**
  - 前端限流：限制请求发送频率
  - 后端限流：当商品卖光了，return了false，直接秒杀结束。
- **库存预热**
  - 提前把商品加载到Redis中，秒杀流程都去操作Redis，等秒杀结束去异步的修改DB。
  - 先读如果有存货，再去扣库存，需要两步。这两步需要具有**原子性。可以使用lua脚本或者pipeline**
- **限流&降级&熔断&隔离**
  - 万一顶不住了。限流可以挡住一部分请求，只服务一部分请求。降级，把资源分配给更重要的请求。熔断，挂掉后做兜底，不会影响其他服务。隔离，通过微服务的形式避免服务间的影响。
- **削峰填谷**
  - 通过MQ对一些耗时但是实时性不高的操作，做异步处理。比如同步缓存到数据库






























