[**首页**](https://github.com/qdw497874677/myNotes/blob/master/首页检索.md)



# 树



## 红黑树

### 二叉查找树

特性

1. 左子树上所有结点的值均小于或等于它的根节点的值。
2. 右子树上所有结点的值均大于或等于它的根结点的值。
3. 左右子树也分别是二叉排序树。

查找和插入利用二分法，最大次数约等于树的高度

缺点：插入数导致数的不平衡，查找和插入效率降低。



**红黑树是一种自平衡的二叉查找树**

特性

1. 节点是红色或黑色
2. 根节点是黑色
3. 每个叶子节点都是黑色空节点（NIL节点）
4. 每个红色节点的两个子节点都是黑色。（从每个叶子到根的所有路径上不能有两个连续的红色节点）
5. 从任一节点到其每个叶子的所有路径都包含相同数目的黑色节点。

这些规则保证：从根节点到叶子节点的最长路径不会超过最短路径的2倍。

在插入和删除节点时，红黑树的规则可能被打破，这时候需要做调整。

# 集合

![image-20200907201053269](数据结构.assets/image-20200907201053269.png)

- Collection
  - Queue
    - Deque
  - List
  - Set

- Map

![image-20200518155247448](Java容器.assets/image-20200518155247448.png)

# ArrayList

## 概述

 ArrayList 是基于数组实现的，所以支持快速随机访问。用一个Object类型的数组存元素。

~~~java
public class ArrayList<E> extends AbstractList<E>
        implements List<E>, RandomAccess, Cloneable, java.io.Serializable
~~~

数组的默认大小为 10。

~~~java
private static final int DEFAULT_CAPACITY = 10;
~~~



## 扩容

添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity >> 1)，也就是旧容量的 1.5 倍。

扩容需要调用 Arrays.copyOf()把原数组复制到新数组中。

~~~java
public boolean add(E e) {
    ensureCapacityInternal(size + 1);  // Increments modCount!!
    elementData[size++] = e;
    return true;
}

private void ensureCapacityInternal(int minCapacity) {
    if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) {
        minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity);
    }
    ensureExplicitCapacity(minCapacity);
}

private void ensureExplicitCapacity(int minCapacity) {
    modCount++;
    // overflow-conscious code
    if (minCapacity - elementData.length > 0)
        grow(minCapacity);
}

private void grow(int minCapacity) {
    // overflow-conscious code
    int oldCapacity = elementData.length;
    int newCapacity = oldCapacity + (oldCapacity >> 1);
    if (newCapacity - minCapacity < 0)
        newCapacity = minCapacity;
    if (newCapacity - MAX_ARRAY_SIZE > 0)
        newCapacity = hugeCapacity(minCapacity);
    // minCapacity is usually close to size, so this is a win:
    elementData = Arrays.copyOf(elementData, newCapacity);
}
~~~



## 删除元素

需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上，然后把数组最后面的引用置为null，该操作的时间复杂度为 O(N)，可以看到 ArrayList 删除元素的代价是非常高的。

~~~java
public E remove(int index) {
    rangeCheck(index);
    modCount++;
    E oldValue = elementData(index);
    int numMoved = size - index - 1;
    if (numMoved > 0)
        System.arraycopy(elementData, index+1, elementData, index, numMoved);
    elementData[--size] = null; // clear to let GC do its work
    return oldValue;
}
~~~



## 线程不安全

~~~java
public class Test4 {
    public static void main(String[] args) {
        List<String> list = new ArrayList<>();
        for (int i = 0; i < 100; i++) {
            new Thread(()->{
                list.add(UUID.randomUUID().toString().substring(0,8));
//                System.out.println(list);
            },String.valueOf(i)).start();

        }
        while (Thread.activeCount()>2){
            Thread.yield();
        }
        System.out.println(list);
    }
}
~~~



### 解决方法

- Vector（加锁的ArrayList）
- Collections.synchronizedList(new ArrayList<>())（通过工具类转换为一个线程安全的集合）
- CopyOnWriteArrayList



# CopyOnWriteArrayList

> 写时复制。读写分离的思想。
>
> 读元素不加锁，array数组用volatile修饰的。
>
> 写入元素的时候，**加锁**，先把原数组复制一份去写，把新元素放到新数组最后。**写完后把原数组引用指向新数组**。
>
> 写的时候是会加锁的。

add方法

~~~java
//array是用volatile修饰的
private transient volatile Object[] array;

public boolean add(E e) {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            Object[] elements = getArray();
            int len = elements.length;
            Object[] newElements = Arrays.copyOf(elements, len + 1);
            newElements[len] = e;
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();
        }
    }
~~~

适合读多写少的场景。

缺点

- 内存占用大。
- 数据不一致：读取不及时。

所以不适合内存敏感，实时性要求很高的场景



# HashSet

HashSet底层是一个初始容量为16，负载因子为0.75的HashMap。用HashMap的key存元素，value是一个Object类型的常量。

## 线程不安全

~~~java
public class Test4 {
    public static void main(String[] args) {
//        List<String> list = new ArrayList<>();
//        List<String> list = Collections.synchronizedList(new ArrayList<>());
//        List<String> list = new CopyOnWriteArrayList<>();
        Set<String> set = new HashSet<>();
        for (int i = 0; i < 100; i++) {
            new Thread(()->{
                set.add(UUID.randomUUID().toString().substring(0,8));
                System.out.println(set);
            },String.valueOf(i)).start();
        }
        while (Thread.activeCount()>2){
            Thread.yield();
        }
        System.out.println(set);
    }
}
~~~



### 解决方法

- Collections.synchronizedSet(new HashSet<>())
- CopyOnWriteArraySet



# CopyOnWriteArraySet

CopyOnWriteArraySet底层是CopyOnWriteArrayList。

add最终会调用CopyOnWriteArrayList中的一个方法，addIfAbsentadd元素前要检查集合中是否包含这个元素。

~~~java
private boolean addIfAbsent(E e, Object[] snapshot) {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            Object[] current = getArray();
            int len = current.length;
            if (snapshot != current) {
                // Optimize for lost race to another addXXX operation
                int common = Math.min(snapshot.length, len);
                for (int i = 0; i < common; i++)
                    if (current[i] != snapshot[i] && eq(e, current[i]))
                        return false;
                if (indexOf(e, current, common, len) >= 0)
                        return false;
            }
            Object[] newElements = Arrays.copyOf(current, len + 1);
            newElements[len] = e;
            setArray(newElements);
            return true;
        } finally {
            lock.unlock();
        }
    }
~~~





# LinkedList

## 概述

基于双向链表，使用Node存储链表节点。

~~~java
private static class Node<E> {
    E item;
    Node<E> next;
    Node<E> prev;
}
~~~

每个链表存储了 first 和 last 指针

~~~java
transient Node<E> first;
transient Node<E> last;
~~~



## 与 ArrayList 的比较

- ArrayList 基于动态数组实现，数组支持随机访问，但插入删除的代价很高，需要移动大量元素。
- LinkedList 基于双向链表实现。链表不支持随机访问，但插入删除只需要改变指针。



# HashMap

默认容量为16，默认装载因子为0.75，扩容后变为之前的2倍。

## 数据结构

有一个Entry（1.8为Node）类型的数组table。Entry存储键值对，组成链表。

HashMap 使用拉链法来解决冲突，同一个链表中存放哈希值和散列桶取模运算结果相同的 Entry。



## 拉链法的工作原理

~~~java
HashMap<String, String> map = new HashMap<>();
map.put("K1", "V1");
map.put("K2", "V2");
map.put("K3", "V3");
~~~

- 新建一个 HashMap，默认大小为 16；
- 插入 <K1,V1> 键值对，先计算 K1 的 hashCode 为 115，将哈希值和数组大小取模，获取余数作为下标 115%16=3。
- 插入 <K2,V2> 键值对，先计算 K2 的 hashCode 为 118，将哈希值和数组大小取模，获取余数作为下标 118%16=6。
- 插入 <K3,V3> 键值对，先计算 K3 的 hashCode 为 118，将哈希值和数组大小取模，获取余数作为下标 118%16=6，头插法插在 <K2,V2> 前面。



## put操作

~~~java
public V put(K key, V value) {
    if (table == EMPTY_TABLE) {
        inflateTable(threshold);
    }
    // 键为 null 单独处理
    if (key == null)
        return putForNullKey(value);
    int hash = hash(key);
    // 确定桶下标
    int i = indexFor(hash, table.length);
    // 先找出是否已经存在键为 key 的键值对，如果存在的话就更新这个键值对的值为 value
    for (Entry<K,V> e = table[i]; e != null; e = e.next) {
        Object k;
        //判断hash相等，并且key用过==相等或者通过equals相等，才算存在相同的key
        if (e.hash == hash && ((k = e.key) == key || key.equals(k))) {
            V oldValue = e.value;
            e.value = value;
            e.recordAccess(this);
            return oldValue;
        }
    }

    modCount++;
    // 插入新键值对，插入i是头插法（1.8之前）
    addEntry(hash, key, value, i);
    return null;
}

final int hash(Object k) {
   int h = hashSeed;
   if (0 != h && k instanceof String) {
       return sun.misc.Hashing.stringHash32((String) k);
   }

   h ^= k.hashCode();
   h ^= (h >>> 20) ^ (h >>> 12);
   return h ^ (h >>> 7) ^ (h >>> 4);
}

static int indexFor(int h, int length) {
   return h & (length-1);
}
~~~

- 如果key为null，单独处理。
- 通过hash()方法获取整形，然后通过int indexFor(int h, int length)方法来获取下标。获取下标的方式是通过取模（位运算）（h & (length-1)，为了使用高效的位运算，所以要求容量capacity为2的幂），获取到数组的下标。
- 遍历链表，检查时候有相同的key，如果有相同，就把value更新。
- 如果没有新建一个键值对，**头插法**（作者认为后放入map的数据被查的可能性更大）放到对应的位置。



## 为什么初始容量为16

为了让根据整形获取下标这个操作更高效。一个数对2^n取模 == 一个数和(2^n - 1)做按位与运算 。但是有些哈希值高位不同低位相同导致单纯的位运算会产生冲突。下面代码为了对key的hashCode进行扰动计算。可以把高位的特征和低位的组合起来，降低哈希冲突的概率。

~~~java
h ^= k.hashCode();
h ^= (h >>> 20) ^ (h >>> 12);
return h ^ (h >>> 7) ^ (h >>> 4);
~~~



## 扩容

### JDK1.7

~~~java
void addEntry(int hash, K key, V value, int bucketIndex) {
    Entry<K,V> e = table[bucketIndex];
    table[bucketIndex] = new Entry<>(hash, key, value, e);
    if (size++ >= threshold)
        resize(2 * table.length);
}

void resize(int newCapacity) {
    Entry[] oldTable = table;
    int oldCapacity = oldTable.length;
    if (oldCapacity == MAXIMUM_CAPACITY) {
        threshold = Integer.MAX_VALUE;
        return;
    }
    Entry[] newTable = new Entry[newCapacity];
    transfer(newTable);
    table = newTable;
    threshold = (int)(newCapacity * loadFactor);
}

// 把就链表数组中的元素转移到新数组中
void transfer(Entry[] newTable) {
    Entry[] src = table;
    int newCapacity = newTable.length;
    for (int j = 0; j < src.length; j++) {
        Entry<K,V> e = src[j];
        if (e != null) {
            src[j] = null;
            do {
                Entry<K,V> next = e.next;
                int i = indexFor(e.hash, newCapacity);
                e.next = newTable[i];
                newTable[i] = e;
                e = next;
            } while (e != null);
        }
    }
}
~~~

- 加入元素后，如果当前元素数量>=临界值（容量*负载因子），就执行扩容resize(int newCapacity)，新容量为旧容量的两倍。
- resize()方法中，先判断旧容量是否为最大容量MAXIMUM_CAPACITY，如果是不扩容了。
- resize()方法中执行transfer()方法把就数组上的元素放到新数组上。遍历数组，如果引用不为空，就把这个链表上的每个节点依次，重新根据新容量计算哈希值，然后用头插法放到新的数组对应位置。



## JDK1.8

主要的改变：

- 链表长度等于8转红黑树，删除时小于等6如果是红黑树就转为链表。
- put时从先插入再扩容，改为先扩容再插入。
- 优化扩容过程。
  - 扩容采用尾插法。扩容时保持链表节点原有的顺序，保持之前节点的引用关系。多线程下扩容就不会产生环了。

1.8 的put过程

~~~java
public V put(K key, V value) {
        return putVal(hash(key), key, value, false, true);
    }
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
    	//如果对应下标的桶是空的，直接把新节点放到这
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            //检查第一个节点hash，然后用==或者equals去比较key，如果相等就用e存着这个节点
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            else if (p instanceof TreeNode)
                //检查第一个节点是不是树的节点，就把新节点加入到树中，e保存插入后对应的节点
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                //既不与第一个节点相等，第一个节点又不是树节点，就遍历所有节点。直到到头或者需要转换为树，或者有相等的节点，直到对应要放新节点的位置，把新节点放上去
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
~~~



## 线程不安全

### 1.7并发扩容

会产生死循环

如果两个线程同时出发扩容，一个线程在移动节点时会导致另一个线程指向链表的两个引用的节点引用顺序相反，在移动节点过程中产生环。

就是说会导致一个线程操作完成后，另一个线程的两个引用指向的节点被反转了。第二个线程扩容时e=next，然后next=e.next，最终导致成环。



### 1.8并发put

假设：两个线程分别将两条对象不同但hash值相同的数据同时put到一个hashmap中，假如hash相同的位置正好为null，两个线程会都对入到对同一位置赋值的操作。假设一个挂起另一个正常插入数据了，挂起的重新获取cpu后，会把之前的数据覆盖掉。



put的时候导致的多线程数据不一致。
 这个问题比较好想象，比如有两个线程A和B，首先A希望插入一个key-value对到HashMap中，首先计算记录所要落到的桶的索引坐标，然后获取到该桶里面的链表头结点，此时线程A的时间片用完了，而此时线程B被调度得以执行，和线程A一样执行，只不过线程B成功将记录插到了桶里面，假设线程A插入的记录计算出来的桶索引和线程B要插入的记录计算出来的桶索引是一样的，那么当线程B成功插入之后，线程A再次被调度运行时，它依然持有过期的链表头但是它对此一无所知，以至于它认为它应该这样做，如此一来就覆盖了线程B插入的记录，这样线程B插入的记录就凭空消失了，造成了数据不一致的行为。

2、另外一个比较明显的线程不安全的问题是HashMap的get操作可能因为resize而引起死循环（cpu100%），具体分析如下：



~~~java
public class Test4 {
    public static void main(String[] args) {
        Map<String,String> map = new HashMap();
        for (int i = 0; i < 100; i++) {
            new Thread(()->{
                map.put(Thread.currentThread().getName(),UUID.randomUUID().toString().substring(0,8));
                System.out.println(map);
            },String.valueOf(i)).start();
        }
        while (Thread.activeCount()>2){
            Thread.yield();
        }
        System.out.println(map);
    }
}
~~~









### 解决方法

- HashTable
  - Hashtable 使用 synchronized 来进行同步。
  - HashMap 可以插入键为 null 的 Entry。
  - HashMap 的迭代器是 fail-fast 迭代器。
  - HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。
- ConcurrentHashMap



# HashTable 

JDK1.7中

HashTable中的hash方法，就是做了一个简单的哈希。

~~~java
private int hash(Object k) {
   // hashSeed will be zero if alternative hashing is disabled.
   return hashSeed ^ k.hashCode();
}
~~~

HashTable中没有indexOf方法，取而代之就是一段代码。就是采用直接取余。

~~~java
int index = (hash & 0x7FFFFFFF) % tab.length;
~~~

HashTable的默认初始大小为11，之后每次扩充为原来的2n+1。 

HashTable会尽量使用素数、奇数作为容量的大小。当数组大小为素数时，**简单的取余结果会更加均匀**。





# （待更新，怎么算size）ConcurrentHashMap

实现上和HashMap类似。

## JDK1.7

ConcurrentHashMap 采用了分段锁技术。数据结构主要是Segment数组和HashEntry数组。Segment 继承ReentrantLock，在ConcurrentHashMap中作为分段锁；HashEntry用于存储键值对数据。HashEntry的结构和HashMap类似，是一种数组和链表的结构（HashEntry作为数组类型和链表节点）。一个Segment中包含一个HashEntry数组，每一个HashEntry是一个链表结构的元素。每个Segment维护着一个HashEntry数组里的元素，当对HashEntry数组里的元素修改时，必须获取与他对应的Segment锁。

多个线程可以同时访问不同分段锁上的数组，从而使其并发度更高（并发度就是 Segment 的个数）。

默认的并发级别为 16，也就是说默认创建 16 个 Segment。

![image-20200514203840948](Java容器.assets/image-20200514203840948.png)

并发度高是因为采用分段锁技术，Segment继承ReentrantLock可重用锁。

size

每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。ConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。

get

将key通过哈希算法后定位到Segment。然后再通过一个哈希算法定位到具体元素（两次哈希方式不一样，前者直接用哈希值，后者对哈希值取高值，为了避免两次哈希值相同）。Segment中的count和hashEntry中的value，都被volatile修饰，线程拿到的总是最新值。get操作只需要读共享变量count和value，所hash有可以不用加锁。

put

- Segment具有锁的功能。首先定位到Segment，如果Segment没有初始化，就通过CAS赋值。然后通过Segment的put向它里面的hashEntry数组中进行插入操作。插入需要经过两个步骤：

  - 通过tryLock()获取Segment的锁，没有获取到就自旋
  - 通过哈希找到对应的位置，作为链表的起点，把value更新到key相等的位置，如果没有就放到第一个为null的位置（链表最后）

  

## JDK1.8

摒弃了Segment，用Node数组+链表+红黑树的数据结构。使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。

链表过长时会转换为红黑树。

采用CAS + synchronized来保证并发安全。HashEntry改为Node，val和next都用volatile关键字修饰。

put

- 根据key计算哈希值。
- 如果数组没有初始化就先通过initTable()初始化。（懒汉）
  - 用CAS，利用volatile修饰的sizeCtl作为互斥标志。如果CAS成功就进入真正初始化逻辑，如果失败发生冲突就yield()(让线程从执行状态改为就绪状态，把自己的时间让出来)
- 根据key定位对应的node，如果为空也就是说没有hash冲突时，就用CAS尝试插入，如果插入不成功就加锁插入。
- 如果存在hash冲突，先检查是否需要扩容，然后就要加锁保证插入线程安全。两种情况
  - 如果是链表形式，就遍历到尾部插入。
  - 如果是红黑树，就按照红黑树的规则插入。
- 如果链表数量大于8，就换成红黑树的结构。
- 统计size加一。

get

- 计算hash值，定位到索引位置，如果是首节点符合就返回
- 如果遇到扩容的时候，会调用标志正在扩容节点ForwardingNode的find方法，查找该节点，匹配就返回
- 如果上面都不符合，就遍历红黑树或者链表找匹配的值返回，如果没有返回null。



~~~java
final V putVal(K key, V value, boolean onlyIfAbsent) {
        if (key == null || value == null) throw new NullPointerException();
        int hash = spread(key.hashCode());
        int binCount = 0;
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                //如果对应的key为空，就尝试用CAS
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            else if ((fh = f.hash) == MOVED)
                //检查是否要扩容
                tab = helpTransfer(tab, f);
            else {
                //否则就用synchronized
                V oldVal = null;
                synchronized (f) {
                    if (tabAt(tab, i) == f) {
                        if (fh >= 0) {
                            binCount = 1;
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = new Node<K,V>(hash, key,
                                                              value, null);
                                    break;
                                }
                            }
                        }
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).putTreeVal(hash, key,
                                                           value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        addCount(1L, binCount);
        return null;
    }
~~~

(待更新)size

通过sumCount()获取。通过遍历CounterCell[]数组中的CounterCell实例，累加CounterCell里面用volatile修饰的value。每次put的最后会执行addCount()



## 红黑树的特点

![img](Java容器.assets/v2-10532295f05d495f1f9c0b2383ebf4a1_720w.jpg)

红黑树查询：其访问性能近似于折半查找，时间复杂度 O(logn)；

- 每个节点要么是红色，要么是黑色，但根节点永远是黑色的；
- 每个红色节点的两个子节点一定都是黑色；
- 红色节点不能连续（也即是，红色节点的孩子和父亲都不能是红色）；
- 从任一节点到其子树中每个叶子节点的路径都包含相同数量的黑色节点；
- 所有的叶节点都是是黑色的（注意这里说叶子节点其实是上图中的 NIL 节点）；



## 转化为红黑树的过程

先将Node替换为TreaNode，然后再将单链表转为双链表。然后调用ThreeNode的treeify方法进行树化。

# LinkedHashMap

承与HashMap、底层使用哈希表与双向链表来保存所有元素。其基本操作与父类HashMap相似，它通过重写父类相关的方法，来实现自己的链接列表特性。



可以用LinkedHashMap实现LRU，重写

~~~java
@Override
    protected boolean removeEldestEntry(Map.Entry<Integer, Integer> eldest) {
        return size()>capacity;
    }
~~~



# （待更新）AQS

AbstractQueuedSynchronizer：抽象队列同步器

~~~java
// 关键的变量，volatile修饰的int类型的变量，用于表示共享资源的状态
	private volatile int state;


	protected final int getState() {
		return state;
	}
    protected final void setState(int newState) {
        state = newState;
    }
    protected boolean tryAcquire(int arg) {
        throw new UnsupportedOperationException();
    }
    protected boolean tryRelease(int arg) {
        throw new UnsupportedOperationException();
    }
~~~



# （待更新）树



## 应用

# BitMap

![img](数据结构.assets/874963-20190930154945790-1681218156.png)

用int作为布尔值数组。

int的每一位表示对应的数存在与否。

## 位置

一个int有4字节，每字节8位，总共32位。所以一个int可以表示32个数是否存在。对于存N个数，可以用int[] aar = int[1+N/32] 去存储。

数字n在Bitmap中对应的位置为arr[n/32]的int中的第n%32位

## 添加

让第i个int中的第j位为1。通过数组下标找到对应的int——arr[ i ]，把1向左移j个位置 1 << j，然后把这个数与arr[ i ]做 | （或）计算。

总结一下：arr[n/32] = arr[n/32] | (1 << (n%32))

## 删除

把1向左移j为，然后按位取反，与int做&操作

arr[n/32] = arr[n/32] & (~(1 << (n%32)))

## 查找

判断对应为位是1还是0。

arr[n/32] & (1 << (n%32)) 是0表示不存在，是1表示存在。

## 场景

### 快速排序

对于没有重复元素的数据排序。把数据放进bitmap中，然后在从低到高或者从高到低取一遍，就达到了排序的目的。O(n)

优点：效率高，占内存少

缺点：需要数据不能重复，数据密集有效率，松散会浪费空间。

### 快速去重

用两个位去表示数字的三种状态：00不存在、01有一个、11有多个。最后统计01的个数。O(n)

### 快速查找

用查找快速知道数存在不存在



# 布隆过滤器

是一种概率型的数据结构，特点是：

- 高效查询和插入
- 能够通过他知道某元素肯定不存在或者可能存在

添加元素：把值的多次不同的hash得到多个索引值，在bit数组中对应的位置设置为1.

查找：做多次hash，得到对应索引，判断索引对应的位的值，如果不都为0说明肯定不存在，如果都为1说明可能存在。

