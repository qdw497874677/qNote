[**首页**](https://github.com/qdw497874677/myNotes/blob/master/首页检索.md)

# 负载均衡

## 概念

将请求分发到多台应用服务器，以此来分散压力的一种架构方式。

## 实现方式

### 重定向

请求都发给前置机，前置机去计算要分配给那个服务器，然后响应给客户端，让客户端重定向。

### 反向代理

请求发给前置机，使用反向代理方式，将请求分发给服务器，客户端不用再请求一次。通常有两种实现，一是交换机实现，另外一种是通过nginx这种软件方式实现

### 数据链路返回

前置机通过给服务器设置虚拟ip和修改mac地址的方式，将请求分发给服务器，服务器处理完直接响应给客户端



## 负载均衡算法

### 轮询法

按请求顺序均匀分配到后端服务器。不关心服务器实际的连接数和当前的系统负载。



### 随机法

通过系统的随机算法，根据服务器的列表大小来随机一台服务器进行访问。访问次数多时，效果类似平均分配。



### 源地址哈希法

根据客户端的ip地址，通过Hash算法得到一个数值，然后对服务器列表大小进行取模，得到服务器序号。这样同一ip当列表不变时，他访问的服务器也不变。



### 加权轮询法

不同的服务器可能配置不相同，抗压能力不同。通过配置不同的权重，去顺序轮询，权重高的会多分配请求。



### 加权随机法

也是加权，通过权重高的随机到的概率高来分配请求



### 最小连接数法

动态选取当前积压连接数少的来处理当前请求。



## 一致性Hash

### 背景

当一个单节点的缓存容量不够后，需要增加节点来分库，对于每个key都映射到对应的节点上。如果分布式集群中有个集群宕机了，对应的key的缓存无法存储导致服务器压力过大。对于增加机器时，又需要保证大部分key在原有映射到的服务器上保持不变。

总结：**如何保证分布式中添加节点和删除节点，对应key的映射保持稳定。可以通过一致性哈希算法解决。**

如果简单的使用普通Hash算法，得到服务器序号，当服务器数量发生变化，对应key算出来序号都会变化。



这种方式要求增加一台缓存服务器时，新的服务器尽量分担存储其他服务器的缓存资源。减少一台缓存服务器时，其他所有服务器可以尽量分担存储它的缓存资源。



### 实现原理

**一致性哈希算法**主要思想：将每个缓存服务器与一个或多个哈希值域区间关联起来，其中区间边界通过计算缓存服务器对应的哈希值来决定。如果一个缓存服务器被移除，则它所对应的区间会被并入到邻近的区间，其他的缓存服务器不需要任何改变。



将映射空间组织成一个环，值的范围为0 - 2^23-1，也就是一个无符号整形的范围。

- 先对服务器进行Hash计算。
- 当请求到来时，对请求进行Hash计算，从计算的哈希值开始顺时针找到第一个服务器的Hash位置，这个服务器就是分配给请求的服务器。

也就是把服务器Hash之前的服务分配给一个服务器。

### 效果

当一个节点A不可用。把他从移除，请求接着顺时针寻找下一个可用节点B。这样原本打到节点A的请求就快速分给节点B，同时不影响打到其他节点的请求。



当需要添加一个节点，比如在A和B中间添加一个C，原本打到B的一部分请求就分配给了，分担了B的请求，同时不影响其他。

### 问题

上面的设置中会有数据倾斜问题。当服务器比较少是，分配在整个区域的位置可能不会很均匀。就会导致请求打到服务器不均匀。

解决：可以在服务器较少的情况下，用多用几个虚拟节点再次映射到对应的服务器上。比如开始只有两个节点A、B。为A和B设置对应的虚拟节点A2、A3、B2、B3，这样总共6个几点，相对会分布均匀一些。对于打到虚拟节点的请求会再次映射到真正的节点上。

# 分布式缓存

缓存的发展：本地缓存 -> 集群缓存 -> 分布式缓存

缓存的好处：

- 加速读写。缓存一般是把数据存到内存中，
- 降低后端负载。阻挡大量请求直接落到系统底层。降低后端对CPU、IO、线程这些资源的需求。

带来的问题：

- 数据不一致：存储层和存储层的数据，存在一定时间窗口一致。时间窗口与缓存的过期时间更新策略有关。
- 代码维护成本：加入缓存层后，要同时处理缓存层和存储层的逻辑。
- 运营成本：为了保证高可用，要做主从，做集群



## 缓存更新



### LRU、LFU、FIFO

这三种算法都是在缓存不够用时采用的更新算法。区别是选择要淘汰的数据的规则不一样。

LRU淘汰最久不访问的数据、LFU淘汰操作频率最低的数据、FIFO先进先出。

一致性差

**使用场景**：适合内存空间有限，数据长期不变动，基本不存在数据不一致性的业务。



### 超时删除

给缓存数据设置一个过期时间。当数据在缓存中不存在后，从数据源重新放到缓存中。

数据一致性一般。

**使用场景**：适合能够容忍一定时间内数据不一致的业务，比如促销活动的描述文案。



### 主动更新

如果数据源有更新，则主动更新缓存。

一致性较高。开发维护成本比较高，**业务数据的更新与缓存更新耦合**到了一起。需要处理业务数据更新成功，缓存更新失败的情景。

为了解耦一般用消息队列的方式来更新。为了提高容错率，会结合超时删除的方案，避免缓存得不到更新的场景。

**使用场景**：对于数据的一致性要求高，比如交易系统，优惠券的总张数。



### 总结

**低一致性业务**：过量删除 + 超时删除

**高一致性业务**：超时删除 + 主动更新



## 缓存穿透、击穿

### 穿透

指查询一个不存在的数据，缓存和数据源存储都不能命中。如果没有做处理，大量的请求可能击垮存储层。

有下面方法：

#### 缓存空对象

如果存储层没有查到，就在缓存层中存储一个空的对象。

问题：

- 如果一瞬间有大量不同的请求，所有的第一次查询还是会穿透到数据层。
- 缓存层中的空对象浪费空间

针对这种方案作出优化：

- 做好业务过滤：通过缩小范围，将越界的请求直接返回，不查询。
- 给缓存的空对象设置较短的过期时间。



#### 布隆过滤器

布隆过滤器是一种Hash和Bitmap结合的数据结构。可以把一个值经过不同的Hash得到几个索引这，映射到Bitmap中，保存为1。如果查询时发现对应Hash后的几个索引位都不全是1，说明肯定是不存在的，但是如果全是1，是不一定存在的。

可以优先判断元素是否存在于集合中，在业务中主动更新布隆过滤器。

使用：可以在本地用布隆过滤器去主动缓存，对于漏判的使用空对象处理。



### 击穿

某个热点数据不可用，导致存储层压力增大。

优化方案：主要是优化热点key的重建

- 互斥锁：同时只允许一个线程对缓存重建。用集群服务用分布式锁。
- 永不过期：更新是独立的，主动更新。
- 后端限流：前两个是知道哪些是热点key的情况。如果不知道还得是后端自己做限流，主要安全的更新一个就好了
- 减少同时过期的key：对一批key的过期时间可以设置为一定范围的随机数。
- 热点key预热：在关键时间提前对一些热点数据更新过期时间等。

### 雪崩

大量缓存数据不可使用，所有请求到达存储层，导致存储层宕机。

优化方案：

- 保证缓存层的高可用：比如Redis集群的哨兵机制
- 为后端限流降级：比如用hystrix。
  - 保证还可以处理少量的请求，用户点一次不行多点几次会有。

















# 分布式锁

在集群中，多台主机都有一个共同的资源，如果不加分布式锁，不同的访问后，他们的结果可能不一样。

分布式锁需要具备的条件

- 一个方法同一时间只能被一台机器的一个线程执行。
  - （Redis）setnx。
- 获取锁，释放锁要高可用高性能。
  - （Redis）setnx。
- 具备可重用。
  - （Redis）在获取锁的时候，判断当前线程是否已经拿到锁了。然后将计数器加减，每获取一次锁加一，每解锁一次减一。
- 具备锁失效机制，防止死锁。
  - （Redis）设置过期时间，为了保证业务完成，每过一定时间重新设置超时时间 ，让业务异步的执行。
- 具备非阻塞锁特性，即没有获得锁可以返回获取锁失败。
  - （Redis）让线程阻塞，然后利用发布订阅解决实时性。



## Redis实现的分布式锁

### Redis

- 加锁

setnx key value

在redis中给key设置一个值，为了避免死锁，给定一个过期时间。保证设置值和过期时间在一个原子操作中。

命令在设置成功时返回1，设置失败时返回0。

- 解锁

将客户端自己的锁的key删除。根据值的uuid和线程自己存的uuid，是否相等，相等就说明是自己的锁，才能解锁。

为了保证原子性，用LUA脚本来完成操作。先判断字符串是否相等，相等就删除key。

缺点：锁不是可重入锁。



## Redisson

~~~java
Rlock product = redisson.getLock("priduct");
product.lock();
priduct.unlock();
~~~





# RPC

## Thrift

# 测试接口的工具

postman、jmeter



## 







