[**首页**](https://github.com/qdw497874677/myNotes/blob/master/首页检索.md)



## 什么是操作系统

- OS是管理计算机硬件和软件资源的程序
- OS屏蔽了硬件层的复杂度
- Kerne（内核）是OS的核心部分，负责系统的**内存**管理，**硬件设备**的管理，**文件系统**的管理以及**应用程序**的管理
- Shell包括GUI、CLI等，是指用户与操作系统进行交互的界面或接口。

## 用户态和内核态

根据进程访问资源的特性，把进程在OS上的运行分为两个级别，是OS的两种运行状态

- 用户态：用户态运行的进程可以直接读取用户程序的数据
- 内核态：内核态运行的进程可以访问计算机的所有资源

### 为什么要分

为了安全，有些指令比较危险，对系统造成的影响比较大，如果所有进程都能调用这些指令，那系统出错的概率就很大。cpu将指令分为特权指令和非特权指令。

## 系统调用

用户写的程序都运行在用户态，在用户态能获取的资源有限，当需要更高级的操作时，需要调用内核态的功能功能接口，然后由操作系统代替完成。用户态的进程请求内核态服务的行为就是系统调用。

按功能大概可分为：

- 设备管理：完成设备的请求、释放、启动等功能
- 文件管理：完成文件的读写创建删除等功能
- 进程管理：完成进程的创建、撤销、阻塞和唤醒等功能
- 进程通讯：完成进程之间的消息传递或信号传递等功能
- 内存管理：完成内存的分配、回收等功能

## 异常

程序执行过程中发生了意想不到的事情，请求操作系统来处理。

常见的有：

- 运行时异常：比如除0
- 恶意访问异常：比如恶意程序想要访问不属于该进程的地址空间
- 死锁

## 中断

计算机执行期间有非寻常或者非预期的急处理事件，使得CPU暂时中断当前正在执行的程序，去执行别的程序，当处理完再回来继续。一般来源于外设或者网络

### 为什么应用程序不能直接访问外设

- OS是可信任的，应用程序不是可信任的，**提高安全性**
- OS屏蔽掉了各种外设的复杂性和差异性，让应用程序**更简洁通用**
- OS能够协调多个程序去调用外设，**避免冲突**

## 进程与线程

### 进程

- 进程的本质：一个具有一定独立功能的**程序在数据集合上的一次动态执行过程**。
- 进程是系统资源分配的单位。每个进程的内存之间相互独立。
- 进程有共有文件和网络句柄。可以打开同一个文件，抢同一个网络端口。

一个进程包含多个线程。

进程包含了一个正在执行中的程序的所有状态信息：

- 程序的代码
- 程序处理的数据：包括存储变量，执行期间分配的内存
- 状态寄存器：比如记录下一条将运行的指令
- 通用寄存器：作为堆、栈
- 系统资源：内存资源、文件系统、网络资源等

进程是一个实体，每一个进程都有它自己的独立的逻辑地址空间，对于进程来说它看的逻辑内存就是全部内存。

#### PCB

进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态，创建和销毁进程都是对PCB的操作。是进程的唯一标识。由三部分组成：

- 进程标识信息：本进程标识、父进程标识、用户标识
- 处理机状态保存区：保存进程运行信息，主要是寄存器和栈指针

### 线程

- 线程是CPU调度和执行的单位，一个进程可以有多个线程，他们可以共享进程的公共资源
- 一个线程包含
  - 栈：存放调用函数的数据，包括参数，返回地址，局部变量
  - PC（程序计数器）：记录当前要执行的指令。指向**内存中，也就是进程的内存**。
  - TLS（线程本地变量）：线程自己的内存，可以用来存放变量。

引入线程可以提高并发度。

#### 为什么要引入线程

#### 单进程的缺陷

- 一次只能执行一个功能，造成系统浪费
- 无法满足某些场景（比如GUI程序）

#### 多进程的问题

- 进程之间通信开销大，因为要通过系统调用切换到内核态。
- 多个进程本身的开销大，包括创建、切换、销毁

通过在进程内增加一类实体来解决上面问题，就引入了线程。相比进程他的上下文切换开销就小了很多

### 区别

- 拥有资源：进程是资源分配的基本单位，但是线程不拥有资源，线程可以访问所属进程的资源。
- 调度：线程是独立调度的基本单位。在同一进程中，线程的切换不会引起进程切换。从一个进程中的线程切换到另一个进程中的线程时，会引起进程调度。
- 系统开销：**创建或撤销进程**时，系统要为其**分配或回收资源**，如内存空间、I/O设备等，付出的开销远大于创建或撤销线程。在进行**进程切换**时，涉及当前执行进程CPU**环境的保存**以及新调度进程的CPU环境的设置；而线程切换时**只需保存和设置少量寄存器内容**，开销小。
- 通信：线程间通信通过读写同一进程中的数据间接通信；进程通信需要借助IPC。



### 线程的实现

#### 用户线程（主流）

线程控制块在用户态的进程中，让进程来管理。

进程通过**用户级别**的库函数完成线程的创建和管理。这种情况下线程与内核无关，内核也感知不到线程

优点：

- 线程不依赖于操作系统，即使操作系统不支持多线程
- 线程切换速度快，因为不用切换到内核态
- 线程的调度可以由进程自行控制

缺点：

- 一个线程阻塞，导致整个进程阻塞。因为对于内核来说，线程就是进程
- OS把时间片分给的是进程，所以多线程下每个线程的时间很少

#### 内核线程

线程控制块在内核态让OS管理，通过系统调用实现线程的创建、调度和销毁。

这种模式下，进程主要完成对资源的管理

缺点：

- 线程切换，一定伴随用户态到内核态，开销比较大

### 轻量级线程



### 协程

协程比线程更加轻量级，不受操作系统内核管理，是完全由程序控制的（用户态执行）。

特点：

- 执行效率高：切换由程序控制，切换开销小。
- 不需要锁机制：因为在一个线程内执行，所以不会有变量冲突，控制共享资源只需要判断状态就好了，效率高。



## 进程状态

![img](操作系统.assets/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f50726f6365737353746174652e706e67)

五种状态

1. 创建状态：进程申请空白的进程控制块（PCB），填写控制管理进程的信息，分配资源，但还没有竞争资源。
2. 就绪状态：进程已经获取到了除CPU之外的所有资源，只有获取CPU资源就能立刻执行。很多就绪状态的进程排成就绪队列。
3. 运行状态：进程已经获取CPU，正在执行
4. 阻塞状态：正在执行的进程由于发生一些事件（IO请求，申请缓冲区失败）暂时无法继续执行，操作系统把处理器分配给另一个就绪状态的进程，而受阻的进程处于的暂停执行的状态就是阻塞状态。
5. 终止状态：当一个进程被终止（自然结束，出现错误，被操作系统终结，被其他有终止权的进程终结）就进入终止状态。终止过程需要两个步骤：先是等待操作系统进行善后处理，然后将其PCB清零返还空间。

### 什么是挂起

**进程被交换到外存**，状态变为挂起状态。

如果是就绪状态被挂起，就是就绪/挂起。调入内存即可执行。

如果是阻塞状态被挂起，就是阻塞/挂起。等待事件出现后会**进入就绪/挂起**状态。

## 为什么进程切换的开销比线程切换大

进程需要很多资源如寄存器，内存，文件等。每当进程切换时，必须考虑保存当前进程的状态并切换。进程切换时要切页表，而且往往伴随着页调度，因为进程的数据段代码要换出去，以便把执行的进程的内容换进来。

- 切换页目录以使用新的地址空间。
- 切换内核栈和硬件上下文。

主要的性能消耗是：

1. 上下文的切换通过操作系统内核来完成。将寄存器中的内容切换出十分消耗性能。
2. 上下文切换回打乱处理器的缓存机制。

进程的内容是线程的超集，上述问题的影响都很小。



## 进程调度算法

### 批处理系统

批处理系统没**有太多的用户操作**，在该系统中，调度算法目标是**保证吞吐量和周转时间**。

- 先来先服务（FCFS）：按照请求的顺序进行调度。
- 短作业优先（SJF）：每一次总是先调度估运行时间最短的作业。
- 最短剩余时间（SRTN）：最短作业优先的抢占式版本。如果新到的任务的估计运行时间比当前剩余时间还要短，就要挂起当前线程，运行新线程。

### 交互式系统

交互式系统**有大量的用户交互**操作，在该系统中调度算法的目标就是**快速进行相应**。

- 时间片轮转：把所有的就绪进程按FCFS排成一个队列，每次调度时，把CPU时间分配给队首进程，当时间片用完计时器发出时钟中断，就停止该进程的执行并放到队尾。
- 优先级调度：对每个线程分配一个优先级，按优先级执行调度。为了防止低优先的进程永远得不到调度，就可以随着时间推移增加等待进程的优先级。
- 多级反馈队列：时间片和优先级的结合。为在时间片轮转中，需要执行多次时间片的进程考虑。根据时间片大小不同设置了**多个队列，时间片依次增大**。进程在第一个队列**没执行完，就会被放到下一个队列**。**队列的优先级依次减小**，前面的队列没有进程任务后，后面的才执行。
  - ![img](操作系统.assets/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67)
- 实时系统：要求一个请求在一个确定时间内得到相应。
  - 分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

## 进程同步

### 临界值

对临界资源进行访问的那段代码成为临界区

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

类似于线程中的同步区域

### 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

### 信号量

信号量（Semaphore）是一个整形变量，可以对其执行down和up操作，也就是常见的P和V操作。

- down：如果信号量大于0，执行-1操作；如果信号量等于0，进程睡眠，等待信号量大于0
- up：对信号量执行+1操作，唤醒睡眠的进程让其完成down操作。

两个操作被设计成原语，不可分割，通常做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为0或者1，那么就成为了**互斥量（Mutex）**，0表示临界区加锁，1表示临界区解锁。

### 管程



## 进程通信（IPC）

和进程同步的区别是

- 进程同步：控制多个进程按一定顺序执行，是一种目的
- 进程通信：进程间传输信息，是一种手段

![img](操作系统.assets/640.webp)

每个进程的用户地址空间都是独立的，但是内核空间是每个进程共享的，进程之间通信需要通过内核。



- 文件
- 信号Signal（kill -9   -15）：软件层次上对中断机制的一种模拟，是一种异步通信方式
  - 信号的处理有三种：
    - 1. 忽略该信号，大多数信号都可以这样处理，SIGKILL、SIGSTOP除外
      2. 捕获信号，用户自定义一个信号处理函数，SIGKILL、SIGSTOP不能被捕获
      3. 系统默认动作，大多数信号的默认动作是终止进程
  - 运行在shell终端的进程，可以通过键盘输入某些组合键，给进程发送信号
    - Ctrl+C产生SIGNT（kill -2）信号，表示中断。终止前台进程
    - Ctrl+Z产生SIGTSTOP信号，表示停止该进程，但还未结束。可以暂停前台进程，不能被阻断
  - 在后台运行的进程，可以通过kill命令给进程发送信号
    - 如：kill -9 PID 给指定PID的进程发送SIGKILL信号，来立刻终结进程，强行终止进程，本信号不能被阻塞、处理和忽略。
- 消息队列：
  - 相比FIFO的优点
    - 独立于读写进程，避免同步管道的打开关闭的肯能产生的困难
    - 避免了FIFO的同步阻塞问题，不需要进程自己提供同步方法
    - 读进程可以根据消息类型有选择地接收消息。
- 管道/命名管道：
  - 管道（匿名管道）：只支持半双工通信（**单相传输**），只能在**父子进程或者兄弟进程**中使用。
    - ps -ef | grep java
    - 是单向的，相互通信需要创建两个，用完了就销毁
  - 命名管道（FIFO）：**去除了管道只能在父子进程中使用的限制**。随意可以在两个进程之间创建两个管道，来实现双向通信。**需要手动创建**，通过mkfifo命令创建管道指定名字。管道是p类型的文件。
    - 创建管道：mkfifo myPipe
    - 写入数据：echo "hello" > myPipe   命令就挺住了，只有当管道里的数据被读完，命令才可以正常退出
    - 读取数据：cat < myPipe   可以看到打印了hello
- 共享内存：**允许多个进程共享一个给定的内存存储区**，数据不需要在进程间复制，是最快的一种IPC。需要使用信号量来同步对共享内存的访问。
- 信号量：是一个计数器，用于为多个进程提供对共享数据对象的访问。
- Socket（最常用的）：可以**跨网络在不同主机的进程之间通信**。主要由三种编程模型
  - 针对TCP协议的Socket编程模型
    - 客户端：
      - 初始化socket，调用connect向服务端指定的地址和端口发送连接请求。连接完成后，通过read、write读写数据
    - 服务端：
      - 初始化serversocket实例，调用bind绑定ip地址和端口，调用listen进行监听，调用accept等待客户端连接，连接成功后得到socket实例，通过read、write读写数据

## （待更新）进程句柄



## 硬链接和软连接的区别

- 硬链接：与普通文件没什么不同，inode（可以理解成指针，指向物理硬盘的一个区块）都指向同一个文件在硬盘中的区块。
- 软链接（符号链接）：保存了其代表的文件的绝对路径，是另一种文件，在硬盘中有独立的区块，访问时替换自身的路径。

## 32位和64位操作系统的区别

进程的寻址空间的大小不同



- 



### 交互式系统

有大量的用户操作，目标是快速响应。

- 时间片轮转
- 优先级调度
- 多级反馈队列

### 实时系统





- 





## 内存管理

### 计算机内存层次的结构

- cpu寄存器
- cpu缓存（L1/L2/L3三层）
- 物理内存
- 磁盘

### 地址空间

分为物理地址空间和逻辑地址空间

- 物理地址空间：由硬件支持的地址空间，从起始地址0，到最大地址MAX
- 逻辑地址空间：一个进程拥有的内存空间范围，最终是要映射到物理地址空间上才能被找到

#### 逻辑地址生成

编译器，将基于符号的地址转换为逻辑地址空间

#### 物理地址生成

物理地址的生成就是指从逻辑地址映射到物理地址的过程，这个具体的映射由CPU中的**内存管理单元（MMU）**来完成，但是整个建立这个映射关系是由OS来完成的。概括为：

1. CPU中的计算逻辑单元ALU**需要某个逻辑地址**的内容
2. MMU完成逻辑地址到物理地址的**映射**
3. 控制器从**总线**发出对该物理地址的内容的**请求**
4. 内存将该请求的内容发给CPU

#### 安全检查

每个进程都有只属于自己进程的逻辑地址空间，不能访问不属于自己的，所以OS要对进程的访问请求做安全检查。OS维护的有每个进程的逻辑地址空间的基址和界限，根据这两项内容来判断是否安全。

### 内存碎片

指物理内存中的一些无法被利用的空间

在内存上，**外部碎片**是位于任何两个**操作系统分配的用于装载进程的内存区域**或页面之间的空闲区域，**内部碎片**是位于一个**操作系统分配的用于装载进程的内存区域**或页面内部的空闲区域。

### 连续内存分配

是一种简单的内存分配策略，给每个进程分配的物理内存中的一块连续的区域。

在早期逻辑地址和地址和物理地址都是连续的，所以当进程多次创建和回收之后，内存中会产生很多内存碎片，很浪费内存空间。所以之后引入了分块和分段

#### 分配策略

分配时，OS会维护一个**空闲分区表**，可以通过快速找到空闲分区，来使用于不同分配策略。

- 首次分配：从低地址开始找，找到第一个能够容纳进程的空闲分区。
  - 优点：实现容易
  - 缺点：容易产生外碎片，分配的速度不稳定（分配大块时速度较慢）
- 最优适配：遍历所有空闲块，寻找能满足进程的最小的空闲分区
  - 优点：避免对大块拆分
  - 缺点：会产生很小的外碎片
- 最差适配：遍历所有的空闲块，寻找能满足进程需求的最大的块，然后分配。
  - 优点：避免了小的外碎片
  - 缺点：优先对大块拆分，不利于大进程的分配

**连续内存分配的缺点：无法避免碎片问题、因为要连续，内存利用率低**

### 非连续内存分配

分配给进程的物理内存空间是不连续的区域

#### 内存管理机制

##### 段式管理

把程序**按内容和构成关系分成段**，每个段内空间要求连续，段之前不要求连续。段的概念：一个段表示访问方式和存储数据的属性相同的一段连续地址空间。

一般进程可以分为以下几个段：

- 栈
- 堆
- 程序数据
- 程序代码（可分为库代码和用户代码）

##### 页式管理

将物理内存和逻辑内存都划分为**大小相同的单元**，其中物理内存中的单元称为帧，逻辑内存中的单元称为页。

每个进程都有一个页表，负责页号到帧号的转换

##### 段页式管理

结合段式和页式的优点，在段式的基础上，给每个段加一级页表。根据段号查段表，得到页号，根据页号查页表得到帧号，帧号+偏移量得到物理地址。

### 虚拟内存

因为主存不够，所以想要**利用外存**，**只将必要的数据装入内存**，**间接扩大了主存的容量**。虚拟内存是一种内存管理技术，它使程序任务他有连续的可用内存，而实际上，真的的空间是被分割成多个物理内存碎片，并且还有部分暂时存储在外存中，在需要的时候进行数据交换。

#### 早期内存不够的解决方案

- 覆盖overlay：程序太大，手动覆盖，选择哪些数据和指令需要驻留在内存中
  - 要求程序员自己手动把程序按照功能划分若干模块，并确定模块间的覆盖关系
- 交换swapping：程序太多，将暂时不用执行的程序反倒外存
  - 交换操作的是整个程序

要实现虚拟页式管理，只需要在页式基础上增加两个核心功能：**请求调页**和**页面置换**页表项中有个重要的标志位：**驻留位**，0表示该也不在内存中

### 局部页面置换算法

如何去管理页面的置换，当把外存中的页加载到内存中，内存空间不足需要选择页面来置换出去。如何选择要置换的页面。

- 最优置换算法（OPT）：预测未来程序访问页面的顺序，将最久不会被访问的页面置换出去。无法实现，只能当做其他算法的评价依据。
- 先进先出置换算法（FIFO）：将内存中驻留时间最长的页面进行置换
- 最近最久未使用（LRU）：将最久没有使用过的页面进行置换。LRU是根据历史推测未来。通常用HashMap+双向链表来实现。
- 时钟置换算法：将所有的页组织成一个环形链表，可以看做是LRU的简单模拟。当缺页时，指针遍历，遇到标记为1就改为0继续遍历，如果标记为0，将做置换。
- 最不常用算法（LFU）：对每个页面都设置一个访问计数器，每访问一次就加一，选择置换计数最少的页。

## 死锁

### 产生死锁的主要原因

> 死锁指多个进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力干涉，它们都将无法推进下去。

安全状态：系统能够按某种进程顺序来为每个进程分配其所需要的资源。

死锁产生的四个必要条件

- 互斥：进程对资源进行排他控制。
- 请求并保持：进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺：进程获得的资源在未使用之前，不能进行剥夺，只能自己释放。
- 环路等待：必然会有进程——资源的环形链。

### 死锁检测

- Jstack命令
- JConsole工具

### 定位死锁

~~~bash
#找到出问题的进程
jps -l
#根据进程id
jstack 进程id
~~~

### 解决死锁

解决死锁的方案有很多，强度由高到低依次是：死锁预防、死锁避免、死锁检测、死锁解决

##### 死锁预防

死锁是由四个必要条件导致的，破坏其中的任意一个条件，死锁情况就应该不会发生了。

1. 破坏互斥条件：不现实。这个需要进程同时访问某些资源，这种方法受限于实际场景，比较难实现，一般都需要对资源独占。
2. 破坏不可抢占条件：允许对资源进行抢夺，比如优先级高的线程需要优先级低的线程的资源，可以要求线程释放资源。但是要在优先级都不相同的条件下才能实现预防死锁，很难找到适用场景。
3. 破坏请求并保持：可行。就是在进程运行之前，一次性申请其所需要的全部资源，然后才能开始运行，从而破坏了“请求”。在分配资源时只要有一种资源不满足就不去占用其他需要的资源，然后进行等待，破坏了“保持”。（显然这种方式导致资源的利用率比较低，进程经常发生饥饿）
4. 破坏循环等待：可行。**对所有资源类型进行分类并排序**，每个进程**按照资源的顺序**进行申请，这样不会新城换。环境比较负责，资源种类优先，不常用

##### 死锁避免

思路就是在一个进程请求资源时进行判断，判断把资源分配给它之后的状态是否是一个安全的状态。安全状态即不会有死锁的状态。如果是安全状态即执行本次分配，如果不是就拒绝本次分配。

- 银行家算法

主要思想就是避免系统进入不安全状态，每次资源分配，首先**检查是否有足够资源满足**。如果有就**先试行分配**，并对分配后的新状态进行安全性检查。如果新状态安全，则正式分配上述资源，否则拒绝分配。

- 指定加锁顺序

如果确保所有线程都是按照相同的顺序获得锁，就不会发生死锁了。这种方式需要事先知道所有可能会用到的锁。

- 加锁时限

在尝试获取锁的时候加一个超时时间，如果在时间内没有获取到锁，就释放所有已经获得的锁，然后等待一段随机的时间后重试。超时锁可以通过自定义锁来实现。超时锁可能带来饥饿的情况。

##### 死锁监测

死锁预防在每次进程申请资源时判断，而死锁检测是**某个特定时期，进行是否死锁的判断**，判断次数更少了。

- 死锁监测

上面两中都不合适的情况下使用。每当一个线程获得了锁，会在线程和锁相关的数据结构中将其记下。每当有线程请求锁，也需要记录在这个数据结构中。当一个线程请求锁失败时，这个线程可以遍历锁的关系图，看是否有死锁发生，如果请求链中包含了自己，就说明发生了死锁。

当检查出死锁时：可以选择释放所有的锁，回退，等待一段随机的时间后重试。（和超时锁的区别是这个只是在检查到死锁后才执行）另一个办法就是给这些线程随机设置优先级，让一个或几个线程回退，剩下的线程就像没发生死锁一样继续保持。

### 模拟死锁代码

~~~java
public class Test8 {
    public static void main(String[] args) {
        String lockA = "lockA";
        String lockB = "lockB";
        new Thread(new HoldLockThread(lockA,lockB)).start();
        new Thread(new HoldLockThread(lockB,lockA)).start();
    }
}
class HoldLockThread implements Runnable{
    private String lockA;
    private String lockB;
    public HoldLockThread(String lockA, String lockB) {
        this.lockA = lockA;
        this.lockB = lockB;
    }
    @Override
    public void run() {
        synchronized (lockA){
            System.out.println(Thread.currentThread().getName()+" 自己持有"+lockA+" 尝试获取；lockB");
            try {
                TimeUnit.SECONDS.sleep(1L);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            synchronized (lockB){
                System.out.println(Thread.currentThread().getName()+" 自己持有"+lockB+" 尝试获取；lockA");
            }
        }
    }
}
~~~



